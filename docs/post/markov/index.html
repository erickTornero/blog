<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Cadena de Markov (MC) - Research blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">
<meta name="google-site-verification" content="jzEUwTDFo-TA-QnHpsX5SEwfkEbP8EbWqLrAi8lEtHc" />
<meta property=”og:site_name” content="Erick Tornero Reinforcement Research blog"  />

<meta name="author" content="Erick Tornero" /><meta name="description" content="La segunda acepción de la RAE nos dice que una secuencia &amp;quot;es una sucesión de cosas que guardan entre sí cierta relación&amp;quot;. En el mundo real podemos encontrar innumerables ejemplos que se ajustan a esta definición. Por ejemplo, en aplicaciónes de transformación de audio a texto y visceverza, pronóstico del clima, en el control de robots o procesamiento de video, etc. En ese sentido, es importante poder abstraer modelos matemáticos que nos permitan estudiar mejor estos procesos.
" /><meta name="keywords" content="reinforcement learning, robotics, deep learning, artificial intelligence, " />






<meta name="generator" content="Hugo 0.76.4 with theme even" />


<link rel="canonical" href="https://ericktornero.github.io/blog/post/markov/" />
<link rel="apple-touch-icon" sizes="180x180" href="/blog/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/blog/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/blog/favicon-16x16.png">
<link rel="manifest" href="/blog/manifest.json">
<link rel="mask-icon" href="/blog/safari-pinned-tab.svg" color="#5bbad5">


<link href="/blog/dist/even.c2a46f00.min.css" rel="stylesheet">

<link rel="stylesheet" href="/blog/css/custom.css">


<meta property="og:title" content="Cadena de Markov (MC)" />
<meta property="og:description" content="La segunda acepción de la RAE nos dice que una secuencia &quot;es una sucesión de cosas que guardan entre sí cierta relación&quot;. En el mundo real podemos encontrar innumerables ejemplos que se ajustan a esta definición. Por ejemplo, en aplicaciónes de transformación de audio a texto y visceverza, pronóstico del clima, en el control de robots o procesamiento de video, etc. En ese sentido, es importante poder abstraer modelos matemáticos que nos permitan estudiar mejor estos procesos." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ericktornero.github.io/blog/post/markov/" />
<meta property="article:published_time" content="2020-03-21T20:13:27-05:00" />
<meta property="article:modified_time" content="2020-03-21T20:13:27-05:00" />
<meta itemprop="name" content="Cadena de Markov (MC)">
<meta itemprop="description" content="La segunda acepción de la RAE nos dice que una secuencia &quot;es una sucesión de cosas que guardan entre sí cierta relación&quot;. En el mundo real podemos encontrar innumerables ejemplos que se ajustan a esta definición. Por ejemplo, en aplicaciónes de transformación de audio a texto y visceverza, pronóstico del clima, en el control de robots o procesamiento de video, etc. En ese sentido, es importante poder abstraer modelos matemáticos que nos permitan estudiar mejor estos procesos.">
<meta itemprop="datePublished" content="2020-03-21T20:13:27-05:00" />
<meta itemprop="dateModified" content="2020-03-21T20:13:27-05:00" />
<meta itemprop="wordCount" content="646">



<meta itemprop="keywords" content="markov,markov-chain," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Cadena de Markov (MC)"/>
<meta name="twitter:description" content="La segunda acepción de la RAE nos dice que una secuencia &quot;es una sucesión de cosas que guardan entre sí cierta relación&quot;. En el mundo real podemos encontrar innumerables ejemplos que se ajustan a esta definición. Por ejemplo, en aplicaciónes de transformación de audio a texto y visceverza, pronóstico del clima, en el control de robots o procesamiento de video, etc. En ese sentido, es importante poder abstraer modelos matemáticos que nos permitan estudiar mejor estos procesos."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/blog/" class="logo">Research Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/blog/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/blog/post/">
        <li class="mobile-menu-item">Posts</li>
      </a><a href="/blog/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/blog/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/blog/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/blog/" class="logo">Research Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/blog/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/blog/post/">Posts</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/blog/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/blog/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/blog/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Cadena de Markov (MC)</h1>

      <div class="post-meta">
        <span class="post-time"> 2020-03-21 </span>
        <div class="post-category">
            <a href="/blog/categories/blogpost/"> blogpost </a>
            </div>
          <span class="more-meta"> 646 words </span>
          <span class="more-meta"> 4 mins read </span>
        
      </div>
    </header>

    
    <div class="post-content">
      <p>La segunda acepción de la <a href="https://dle.rae.es/secuencia?m=form">RAE</a> nos dice que una <strong>secuencia</strong> <em>&quot;es una sucesión de cosas que guardan entre sí cierta relación&quot;</em>. En el mundo real podemos encontrar innumerables ejemplos que se ajustan a esta definición. Por ejemplo, en aplicaciónes de transformación de audio a texto y visceverza, pronóstico del clima, en el control de robots o procesamiento de video, etc. En ese sentido, es importante poder abstraer modelos matemáticos que nos permitan estudiar mejor estos procesos.</p>

<figure>
    <img src="/blog/images/helloworld.gif"
         alt="Sistema secuencial de sugerencia de texto"/> <figcaption>
            <p>Sistema secuencial de sugerencia de texto</p>
        </figcaption>
</figure>


<h2 id="el-problema-de-la-dimensionalidad">El problema de la dimensionalidad</h2>

<p>El siguiente grafo, o propiamente dicho: <em>Modelo Gráfico probabilistico</em> (PGM) representa un sistema secuencial de longitud de secuencia <span  class="math">\(T=4\)</span>.</p>

<figure>
    <img src="/blog/images/sequential_model.png"
         alt="Modelo de un sistema secuencial sin ninguna asumpción"/> <figcaption>
            <p>Modelo de un sistema secuencial sin ninguna asumpción</p>
        </figcaption>
</figure>


<p>Siguiendo la regla de la cadena para un modelo de longitud arbitraria <span  class="math">\(T\)</span> se obtiene la probabilidad de dicho evento.</p>

<p><span  class="math">\[p(x_{1:T}) = p(x_1)p(x_2|x_1)p(x_3|x_2,x_1)\cdots p(x_T|x_{1:T-1})\]</span></p>

<p>El número de parametros para resolver este problema es del orden de <span  class="math">\(O(M^T)\)</span>, siendo M el número de estados y T el orden de la secuencia. De aqui que el número de parametros se incremente exponencial a medidad que crecen los estados y el orden de la secuencia, lo que hace impráctico este tipo de soluciónes para problemas que empiezen a crecer en complejidad.</p>

<h2 id="markov-chain-y-la-asumpción-de-independencia">Markov Chain y la asumpción de independencia</h2>

<p>En el ejemplo anterior vimos que un modelo sin ninguna asumpción puede requerir una cantidad muy grande de parametros. Markov Chain es una forma en como podemos plasmar un modelo secuencial de una forma sencilla bajo la asumpción de que la probabilidad que ocurra un estado <span  class="math">\(x_t\)</span> en un tiempo determinado <span  class="math">\(t\)</span> únicamente depende de lo que ocurre un instante anterior <span  class="math">\(x_{t-1}\)</span>, como se puede ver en la ecuación y grafo siguiente. Bajo esta asumpción se reduce el número de parametros a <span  class="math">\(O(K^2)\)</span>, como veremos más adelante esto es: una matriz cuadrada de dimensión 2.</p>

<p><span  class="math">\[p(x_t|x_{t-1})\]</span></p>

<figure>
    <img src="/blog/images/mdp_pgm.png"
         alt="Modelo Gráfico Probabilistico de una Cadena de Markov, note que cada estádo depende únicamente del estado anterior a excepción del primer estado."/> <figcaption>
            <p>Modelo Gráfico Probabilistico de una Cadena de Markov, note que cada estádo depende únicamente del estado anterior a excepción del primer estado.</p>
        </figcaption>
</figure>


<p>Por lo que podemos escribir la probabilidad de un evento (secuencia de estádos) <span  class="math">\(x_1, x_2, x_3, \cdots,x_T\)</span> que sigue un proceso markoviano tiene la forma:</p>

<p><span  class="math">\[p(x_{1:T}) = p(x_1)\prod_{t=2}^T p(x_t|x_{t-1})\]</span></p>

<p>Donde <span  class="math">\(p(x_1)\)</span> es la probabilidad de que dicho evento empieze en el estado <span  class="math">\(x_1\)</span>.</p>

<p>Nótese que la <strong>asumpción de markov</strong> de que <em>el estado siguiente solo depende del estado actual</em> únicamente es cierto cuando se conoce el estado actual. En otras palabras, <em>&quot;el estado siguiente es independiente de los estádos anteriores dado que se conoce el estádo actual&quot;</em>, es decir <span  class="math">\(x_{t+1} \perp x_{1:t-1} | x_t\)</span>.</p>

<p>Esto puede ser una asumpción fuerte para ciertas aplicaciones que implica que en cada estado conocemos toda la información necesaria para predecir el estádo siguiente.. Por ejemplo, consideremos que estamos intentando obtener la posición de un robot mediante una cámara. Definimos que el estado actual son los pixeles del frame actual <span  class="math">\(x_t = F_t\)</span>, se puede intuir que este sistema no cumpliría con la propiedad de markov, ya que los pixeles de un único frame no nos informa de hacia donde se mueve el objeto por lo que no se podría saber cual es la posición en <span  class="math">\(t+1\)</span>.</p>

<p>Una solución para escenarios donde no se cumple la propiedad de Markov es utilizar cadenas de markov de órdenes mayores a uno. Por ejemplo una cadena de Markov de segundo orden tiene la siguiente propiedad: <span  class="math">\(p(x_t|x_{t-1}, x_{t-2})\)</span>, es decir: el estado actual depende de los 2 estados anteriores. En ese sentido, uno podría pensar aumentar el orden de la cadena, pero nótese que el caso extremo es el presentado en el primer ejemplo, donde se tiene <span  class="math">\(O(M^K)\)</span> parámetros.</p>

<p>Existen otros métodos como los <em>Modelos Ocultos de Markov (HMM)</em>, que estan diseñados para solucionar estas dependencias o correlaciones con los estádos anteriores, o cuando las entradas son ruidosas. Esto lo veremos en otro post.</p>

<h2 id="referencias">Referencias</h2>

<p>[1] Kevin P. Murphy. <strong>Machine Learning: A probabilistic Perspective</strong>, <em>First edition</em>, <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/38136.pdf">2012</a>.</p>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Erick Tornero</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2020-03-21
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/blog/tags/markov/">markov</a>
          <a href="/blog/tags/markov-chain/">markov-chain</a>
          </div>
      <nav class="post-nav">
        
        <a class="next" href="/blog/post/ambrl/">
            <span class="next-text nav-default">Advances in Model Based Reinforcement Learning</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:erick.tornero@ucsp.edu.pe" class="iconfont icon-email" title="email"></a>
      <a href="https://www.twitter.com/erickTorneroT" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://www.linkedin.com/in/ericktornero/" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="http://www.github.com/ericktornero" class="iconfont icon-github" title="github"></a>
  <a href="https://ericktornero.github.io/blog/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">erickTornero</span>
  </span>
  
</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css" integrity="sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.js" integrity="sha384-2BKqo+exmr9su6dir+qCw08N2ZKRucY4PrGQPPWU1A7FtlCGjmEGFqXCv5nyM5Ij" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script type="text/javascript" src="/blog/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/blog/lib/slideout/slideout-1.0.1.min.js"></script>
  
<script type="text/javascript" src="/blog/dist/even.26188efa.min.js"></script>








</body>
</html>
